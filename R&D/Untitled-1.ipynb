{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of foggy images: 10\n",
      "Number of clear images: 10\n",
      "Preprocessed foggy images shape: (10, 32, 32, 3)\n",
      "Preprocessed clear images shape: (10, 32, 32, 3)\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "Cannot handle this data type: (1, 1, 3), <f4",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\pm3bap\\lib\\site-packages\\PIL\\Image.py:3080\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   3079\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 3080\u001b[0m     mode, rawmode \u001b[39m=\u001b[39m _fromarray_typemap[typekey]\n\u001b[0;32m   3081\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mKeyError\u001b[0m: ((1, 1, 3), '<f4')",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 127\u001b[0m\n\u001b[0;32m    124\u001b[0m preprocessed_clear_images \u001b[39m=\u001b[39m preprocessed_clear_images\u001b[39m.\u001b[39mastype(\u001b[39m'\u001b[39m\u001b[39mfloat32\u001b[39m\u001b[39m'\u001b[39m) \u001b[39m/\u001b[39m \u001b[39m255.0\u001b[39m\n\u001b[0;32m    126\u001b[0m \u001b[39m# Train the DehazeNet using supervised learning\u001b[39;00m\n\u001b[1;32m--> 127\u001b[0m model \u001b[39m=\u001b[39m supervised_train(preprocessed_foggy_images, preprocessed_clear_images, num_epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m30\u001b[39;49m)\n\u001b[0;32m    129\u001b[0m \u001b[39m# Now you can use the trained model for fog removal on new foggy images\u001b[39;00m\n\u001b[0;32m    130\u001b[0m \u001b[39m# Assuming you have a new foggy image: foggy_image_path\u001b[39;00m\n\u001b[0;32m    131\u001b[0m foggy_image_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Fog/foggy-001.jpg\u001b[39m\u001b[39m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[21], line 84\u001b[0m, in \u001b[0;36msupervised_train\u001b[1;34m(foggy_images, clear_images, num_epochs, batch_size)\u001b[0m\n\u001b[0;32m     82\u001b[0m target_size \u001b[39m=\u001b[39m foggy_images\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m     83\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m clear_images:\n\u001b[1;32m---> 84\u001b[0m     resized_image \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(Image\u001b[39m.\u001b[39;49mfromarray(image)\u001b[39m.\u001b[39mresize((target_size, target_size)))\n\u001b[0;32m     85\u001b[0m     resized_clear_images\u001b[39m.\u001b[39mappend(resized_image)\n\u001b[0;32m     87\u001b[0m \u001b[39m# Convert lists to numpy arrays\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\pm3bap\\lib\\site-packages\\PIL\\Image.py:3083\u001b[0m, in \u001b[0;36mfromarray\u001b[1;34m(obj, mode)\u001b[0m\n\u001b[0;32m   3081\u001b[0m     \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m   3082\u001b[0m         msg \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mCannot handle this data type: \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m, \u001b[39m\u001b[39m%s\u001b[39;00m\u001b[39m\"\u001b[39m \u001b[39m%\u001b[39m typekey\n\u001b[1;32m-> 3083\u001b[0m         \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(msg) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m   3084\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   3085\u001b[0m     rawmode \u001b[39m=\u001b[39m mode\n",
      "\u001b[1;31mTypeError\u001b[0m: Cannot handle this data type: (1, 1, 3), <f4"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "\n",
    "def build_dehazenet_model(target_size, num_channels):\n",
    "    model = models.Sequential()\n",
    "    # Define your DehazeNet model architecture\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(target_size, target_size, num_channels)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # Upsampling layers\n",
    "    model.add(layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(num_channels, (3, 3), activation='sigmoid', padding='same'))  # Output with 3 channels (RGB)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "def preprocess_image(image, target_size):\n",
    "    # Resize the image to the target size\n",
    "    resized_image = image.resize((target_size, target_size))\n",
    "\n",
    "    # Convert the image to grayscale if it has an alpha channel\n",
    "    if resized_image.mode == 'RGBA':\n",
    "        resized_image = resized_image.convert('RGB')\n",
    "\n",
    "    # Convert the image to numpy array\n",
    "    image_array = np.array(resized_image)\n",
    "\n",
    "    # If the image has only 2 dimensions, expand it to have a third dimension\n",
    "    if len(image_array.shape) == 2:\n",
    "        image_array = np.expand_dims(image_array, axis=2)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder_path):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = Image.open(image_path)\n",
    "            if image is not None:\n",
    "                images.append(image)\n",
    "    return images\n",
    "\n",
    "\n",
    "def preprocess_images(images, target_size):\n",
    "    preprocessed_images = []\n",
    "    for image in images:\n",
    "        preprocessed_image = preprocess_image(image, target_size)\n",
    "        preprocessed_images.append(preprocessed_image)\n",
    "\n",
    "    # Find the maximum shape among all preprocessed images\n",
    "    max_shape = max([image.shape for image in preprocessed_images])\n",
    "\n",
    "    # Resize all preprocessed images to the maximum shape\n",
    "    resized_images = []\n",
    "    for image in preprocessed_images:\n",
    "        resized_image = np.pad(image, ((0, max_shape[0] - image.shape[0]),\n",
    "                                       (0, max_shape[1] - image.shape[1]),\n",
    "                                       (0, max_shape[2] - image.shape[2])),\n",
    "                               mode='constant')\n",
    "        resized_images.append(resized_image)\n",
    "\n",
    "    # Convert the list of preprocessed images to a NumPy array\n",
    "    preprocessed_images = np.array(resized_images)\n",
    "    return preprocessed_images\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def supervised_train(foggy_images, clear_images, num_epochs, batch_size):\n",
    "    # Resize clear images to match the size of foggy images\n",
    "    resized_clear_images = []\n",
    "    target_size = foggy_images.shape[1]\n",
    "    for image in clear_images:\n",
    "        resized_image = np.array(Image.fromarray(image).resize((target_size, target_size)))\n",
    "        resized_clear_images.append(resized_image)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    foggy_images = np.array(foggy_images)\n",
    "    clear_images = np.array(resized_clear_images)\n",
    "\n",
    "    # Build and compile the DehazeNet model\n",
    "    num_channels = foggy_images.shape[3]\n",
    "    model = build_dehazenet_model(target_size, num_channels)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the DehazeNet model using supervised learning\n",
    "    model.fit(foggy_images, clear_images, epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    foggy_folder_path = \"C:/Users/HP/Pictures/clearFoggy/Foggy/\"  # Specify the folder path containing the foggy images\n",
    "    clear_folder_path = \"C:/Users/HP/Pictures/clearFoggy/Clear/\"  # Specify the folder path containing the clear images\n",
    "\n",
    "    foggy_images = load_images_from_folder(foggy_folder_path)\n",
    "    clear_images = load_images_from_folder(clear_folder_path)\n",
    "\n",
    "    print(\"Number of foggy images:\", len(foggy_images))\n",
    "    print(\"Number of clear images:\", len(clear_images))\n",
    "\n",
    "    target_size = 32  # Specify the desired target size for preprocessing\n",
    "\n",
    "    preprocessed_foggy_images = preprocess_images(foggy_images, target_size)\n",
    "    preprocessed_clear_images = preprocess_images(clear_images, target_size)\n",
    "\n",
    "    print(\"Preprocessed foggy images shape:\", preprocessed_foggy_images.shape)\n",
    "    print(\"Preprocessed clear images shape:\", preprocessed_clear_images.shape)\n",
    "\n",
    "    # Normalize pixel values to [0, 1]\n",
    "    preprocessed_foggy_images = preprocessed_foggy_images.astype('float32') / 255.0\n",
    "    preprocessed_clear_images = preprocessed_clear_images.astype('float32') / 255.0\n",
    "\n",
    "    # Train the DehazeNet using supervised learning\n",
    "    model = supervised_train(preprocessed_foggy_images, preprocessed_clear_images, num_epochs=10, batch_size=30)\n",
    "\n",
    "    # Now you can use the trained model for fog removal on new foggy images\n",
    "    # Assuming you have a new foggy image: foggy_image_path\n",
    "    foggy_image_path = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Fog/foggy-001.jpg\"\n",
    "    foggy_image = Image.open(foggy_image_path)\n",
    "    preprocessed_foggy_image = preprocess_image(foggy_image, target_size)\n",
    "    normalized_foggy_image = preprocessed_foggy_image.astype('float32') / 255.0\n",
    "    dehazed_image = model.predict(np.expand_dims(normalized_foggy_image, axis=0))[0]\n",
    "\n",
    "    # Display the dehazed image\n",
    "    plt.imshow(dehazed_image)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of foggy images: 10\n",
      "Number of clear images: 10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot resize an array that references or is referenced\nby another array in this way.\nUse the np.resize function or refcheck=False",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 116\u001b[0m\n\u001b[0;32m    113\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mNumber of clear images:\u001b[39m\u001b[39m\"\u001b[39m,\u001b[39mlen\u001b[39m(clear_images))\n\u001b[0;32m    115\u001b[0m \u001b[39m# Preprocess the images\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m foggy_images \u001b[39m=\u001b[39m preprocess_images(foggy_images, target_size)\n\u001b[0;32m    117\u001b[0m clear_images \u001b[39m=\u001b[39m preprocess_images(clear_images, target_size)\n\u001b[0;32m    119\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mShape of preprocessed foggy images:\u001b[39m\u001b[39m\"\u001b[39m, foggy_images\u001b[39m.\u001b[39mshape)\n",
      "Cell \u001b[1;32mIn[14], line 60\u001b[0m, in \u001b[0;36mpreprocess_images\u001b[1;34m(images, target_size)\u001b[0m\n\u001b[0;32m     58\u001b[0m preprocessed_images \u001b[39m=\u001b[39m []\n\u001b[0;32m     59\u001b[0m \u001b[39mfor\u001b[39;00m image \u001b[39min\u001b[39;00m images:\n\u001b[1;32m---> 60\u001b[0m     preprocessed_image \u001b[39m=\u001b[39m preprocess_image(image, target_size)\n\u001b[0;32m     61\u001b[0m     preprocessed_images\u001b[39m.\u001b[39mappend(preprocessed_image\u001b[39m.\u001b[39mcopy())  \u001b[39m# Create a copy of the preprocessed image\u001b[39;00m\n\u001b[0;32m     62\u001b[0m                                                            \u001b[39m# to avoid modifying the original image array\u001b[39;00m\n\u001b[0;32m     63\u001b[0m \n\u001b[0;32m     64\u001b[0m \u001b[39m# Find the maximum shape among all preprocessed images\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[14], line 29\u001b[0m, in \u001b[0;36mpreprocess_image\u001b[1;34m(image, target_size)\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mpreprocess_image\u001b[39m(image, target_size):\n\u001b[0;32m     28\u001b[0m     \u001b[39m# Resize the image to the target size\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m     resized_image \u001b[39m=\u001b[39m image\u001b[39m.\u001b[39;49mresize(( target_size, target_size))\n\u001b[0;32m     31\u001b[0m     \u001b[39m# Convert the image to grayscale if it has an alpha channel\u001b[39;00m\n\u001b[0;32m     32\u001b[0m     \u001b[39mif\u001b[39;00m resized_image\u001b[39m.\u001b[39mmode \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mRGBA\u001b[39m\u001b[39m'\u001b[39m:\n",
      "\u001b[1;31mValueError\u001b[0m: cannot resize an array that references or is referenced\nby another array in this way.\nUse the np.resize function or refcheck=False"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "def build_dehazenet_model(target_size, num_channels):\n",
    "    model = models.Sequential()\n",
    "    # Define your DehazeNet model architecture\n",
    "    \n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(target_size, target_size, num_channels)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # Add more convolutional layers as needed\n",
    "    \n",
    "    # Upsampling layers\n",
    "    model.add(layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(num_channels, (3, 3), activation='sigmoid', padding='same'))  # Output with 3 channels (RGB)\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess_image(image, target_size):\n",
    "    # Resize the image to the target size\n",
    "    resized_image = image.resize(( target_size, target_size))\n",
    "\n",
    "    # Convert the image to grayscale if it has an alpha channel\n",
    "    if resized_image.mode == 'RGBA':\n",
    "        resized_image = resized_image.convert('RGB')\n",
    "\n",
    "    # Convert the image to numpy array\n",
    "    image_array = np.array(resized_image)\n",
    "\n",
    "    # If the image has only 2 dimensions, expand it to have a third dimension\n",
    "    if len(image_array.shape) == 2:\n",
    "        image_array = np.expand_dims(image_array, axis=2)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "\n",
    "def load_images_from_folder(folder_path, target_size):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if filename.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            image_path = os.path.join(folder_path, filename)\n",
    "            image = Image.open(image_path)\n",
    "            if image is not None:\n",
    "                preprocessed_image = preprocess_image(image, target_size)\n",
    "                images.append(preprocessed_image)\n",
    "    return images\n",
    "\n",
    "\n",
    "def preprocess_images(images, target_size):\n",
    "    preprocessed_images = []\n",
    "    for image in images:\n",
    "        preprocessed_image = preprocess_image(image, target_size)\n",
    "        preprocessed_images.append(preprocessed_image.copy())  # Create a copy of the preprocessed image\n",
    "                                                               # to avoid modifying the original image array\n",
    "\n",
    "    # Find the maximum shape among all preprocessed images\n",
    "    max_shape = max([image.shape for image in preprocessed_images])\n",
    "\n",
    "    # Resize all preprocessed images to the maximum shape\n",
    "    resized_images = []\n",
    "    for image in preprocessed_images:\n",
    "        resized_image = np.pad(image, ((0, max_shape[0] - image.shape[0]),\n",
    "                                       (0, max_shape[1] - image.shape[1]),\n",
    "                                       (0, max_shape[2] - image.shape[2])),\n",
    "                               mode='constant')\n",
    "        resized_images.append(resized_image)\n",
    "\n",
    "    # Convert the list of preprocessed images to a NumPy array\n",
    "    preprocessed_images = np.array(resized_images)\n",
    "    return preprocessed_images\n",
    "\n",
    "\n",
    "def supervised_train(foggy_images, clear_images, num_epochs, batch_size, target_size):\n",
    "    # Resize clear images to match the size of foggy images\n",
    "    resized_clear_images = []\n",
    "    for image in clear_images:\n",
    "        resized_image = np.array(Image.fromarray(image).resize((target_size, target_size)))\n",
    "        resized_clear_images.append(resized_image)\n",
    "\n",
    "    # Convert lists to numpy arrays\n",
    "    foggy_images = np.array(foggy_images)\n",
    "    clear_images = np.array(resized_clear_images)\n",
    "\n",
    "    # Build and compile the DehazeNet model\n",
    "    num_channels = foggy_images.shape[3]\n",
    "    model = build_dehazenet_model(target_size, num_channels)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the DehazeNet model using supervised learning\n",
    "    model.fit(foggy_images, clear_images, epochs=num_epochs, batch_size=batch_size)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    foggy_folder_path = \"C:/Users/HP/Pictures/clearFoggy/Foggy\"  # Specify the folder path containing the foggy images\n",
    "    clear_folder_path = \"C:/Users/HP/Pictures/clearFoggy/Clear\"  # Specify the folder path containing the clear images\n",
    "\n",
    "    target_size = 32  # Specify the desired target size for preprocessing\n",
    "\n",
    "    foggy_images = load_images_from_folder(foggy_folder_path, target_size)\n",
    "    clear_images = load_images_from_folder(clear_folder_path, target_size)\n",
    "\n",
    "    print(\"Number of foggy images:\", len(foggy_images))\n",
    "    print(\"Number of clear images:\",len(clear_images))\n",
    "\n",
    "    # Preprocess the images\n",
    "    foggy_images = preprocess_images(foggy_images, target_size)\n",
    "    clear_images = preprocess_images(clear_images, target_size)\n",
    "\n",
    "    print(\"Shape of preprocessed foggy images:\", foggy_images.shape)\n",
    "    print(\"Shape of preprocessed clear images:\", clear_images.shape)\n",
    "\n",
    "    # Train the DehazeNet model\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "    model = supervised_train(foggy_images, clear_images, num_epochs, batch_size, target_size)\n",
    "\n",
    "    # Evaluate the DehazeNet model on a test image (optional)\n",
    "    test_image_path = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Fog/foggy-001.jpg\"\n",
    "    test_image = Image.open(test_image_path)\n",
    "    test_foggy_image = preprocess_image(test_image, target_size)\n",
    "    test_foggy_image = np.expand_dims(test_foggy_image, axis=0)\n",
    "    predicted_clear_image = model.predict(test_foggy_image)\n",
    "    plt.imshow(test_foggy_image[0])\n",
    "    plt.show()\n",
    "    plt.imshow(predicted_clear_image[0])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of foggy images: 10\n",
      "Number of clear images: 10\n",
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 184\u001b[0m\n\u001b[0;32m    182\u001b[0m num_epochs \u001b[39m=\u001b[39m \u001b[39m10\u001b[39m\n\u001b[0;32m    183\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m32\u001b[39m\n\u001b[1;32m--> 184\u001b[0m model \u001b[39m=\u001b[39m supervised_train(foggy_folder_path, clear_folder_path, num_epochs, batch_size, target_size)\n\u001b[0;32m    186\u001b[0m \u001b[39m# Evaluate the DehazeNet model on a test image (optional)\u001b[39;00m\n\u001b[0;32m    187\u001b[0m test_image_path \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mC:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Fog/foggy-001.jpg\u001b[39m\u001b[39m\"\u001b[39m\n",
      "Cell \u001b[1;32mIn[20], line 157\u001b[0m, in \u001b[0;36msupervised_train\u001b[1;34m(foggy_folder_path, clear_folder_path, num_epochs, batch_size, target_size)\u001b[0m\n\u001b[0;32m    155\u001b[0m \u001b[39m# Train the DehazeNet model using supervised learning\u001b[39;00m\n\u001b[0;32m    156\u001b[0m early_stopping \u001b[39m=\u001b[39m callbacks\u001b[39m.\u001b[39mEarlyStopping(patience\u001b[39m=\u001b[39m\u001b[39m3\u001b[39m, restore_best_weights\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m--> 157\u001b[0m model\u001b[39m.\u001b[39;49mfit(\n\u001b[0;32m    158\u001b[0m     train_generator,\n\u001b[0;32m    159\u001b[0m     epochs\u001b[39m=\u001b[39;49mnum_epochs,\n\u001b[0;32m    160\u001b[0m     steps_per_epoch\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(train_images) \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m batch_size,\n\u001b[0;32m    161\u001b[0m     validation_data\u001b[39m=\u001b[39;49mval_generator,\n\u001b[0;32m    162\u001b[0m     validation_steps\u001b[39m=\u001b[39;49m\u001b[39mlen\u001b[39;49m(val_images) \u001b[39m/\u001b[39;49m\u001b[39m/\u001b[39;49m batch_size,\n\u001b[0;32m    163\u001b[0m     callbacks\u001b[39m=\u001b[39;49m[early_stopping]\n\u001b[0;32m    164\u001b[0m )\n\u001b[0;32m    166\u001b[0m \u001b[39mreturn\u001b[39;00m model\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\pm3bap\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\pm3bap\\lib\\site-packages\\keras\\engine\\training.py:1576\u001b[0m, in \u001b[0;36mModel.fit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1574\u001b[0m logs \u001b[39m=\u001b[39m tf_utils\u001b[39m.\u001b[39msync_to_numpy_or_python_type(logs)\n\u001b[0;32m   1575\u001b[0m \u001b[39mif\u001b[39;00m logs \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m-> 1576\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[0;32m   1577\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUnexpected result of `train_function` \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1578\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m(Empty logs). Please use \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1579\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`Model.compile(..., run_eagerly=True)`, or \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1580\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m`tf.config.run_functions_eagerly(True)` for more \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1581\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39minformation of where went wrong, or file a \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1582\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39missue/bug to `tf.keras`.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m   1583\u001b[0m     )\n\u001b[0;32m   1584\u001b[0m epoch_logs \u001b[39m=\u001b[39m copy\u001b[39m.\u001b[39mcopy(logs)\n\u001b[0;32m   1586\u001b[0m \u001b[39m# Run validation.\u001b[39;00m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "from PIL import Image\n",
    "\n",
    "import os\n",
    "import glob\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img, ImageDataGenerator\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from tensorflow.keras.applications.imagenet_utils import preprocess_input\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "def build_dehazenet_model(target_size, num_channels):\n",
    "    \"\"\"\n",
    "    Build the DehazeNet model architecture.\n",
    "\n",
    "    Parameters:\n",
    "        target_size (int): the size of the input images (assumed to be square).\n",
    "        num_channels (int): the number of color channels in the input images (usually 3 for RGB).\n",
    "\n",
    "    Returns:\n",
    "        a Keras model object.\n",
    "    \"\"\"\n",
    "    model = models.Sequential()\n",
    "\n",
    "    # Convolutional layers\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(target_size, target_size, num_channels)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    # Add more convolutional layers as needed\n",
    "\n",
    "    # Upsampling layers\n",
    "    model.add(layers.Conv2DTranspose(64, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2DTranspose(32, (3, 3), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2D(num_channels, (3, 3), activation='sigmoid', padding='same'))  # Output with 3 channels (RGB)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "def preprocess_image(image, target_size):\n",
    "    \"\"\"\n",
    "    Preprocess an image by resizing it to the target size and converting it to a NumPy array.\n",
    "\n",
    "    Parameters:\n",
    "        image (PIL.Image): the input image.\n",
    "        target_size (int): the size to which the image should be resized (assumed to be square).\n",
    "\n",
    "    Returns:\n",
    "        a NumPy array representing the preprocessed image.\n",
    "    \"\"\"\n",
    "    # Resize the image to the target size\n",
    "    resized_image = image.resize((target_size, target_size))\n",
    "\n",
    "    # Convert the image to grayscale if it has an alpha channel\n",
    "    if resized_image.mode == 'RGBA':\n",
    "        resized_image = resized_image.convert('RGB')\n",
    "\n",
    "    # Convert the image to numpy array\n",
    "    image_array = np.array(resized_image)\n",
    "\n",
    "    # If the image has only 2 dimensions, expand it to have a third dimension\n",
    "    if len(image_array.shape) == 2:\n",
    "        image_array = np.expand_dims(image_array, axis=2)\n",
    "\n",
    "    return image_array\n",
    "\n",
    "class ImageSequence(Sequence):\n",
    "    \"\"\"\n",
    "    A Keras-compatible data generator that loads and preprocesses images in batches.\n",
    "\n",
    "    Parameters:\n",
    "        images (list of tuples): a list of tuples containing the input and target images.\n",
    "        batch_size (int): the batch size to use during training.\n",
    "        shuffle (bool): whether to shuffle the data between epochs.\n",
    "        target_size (int): the size to which the images should be resized (assumed to be square).\n",
    "    \"\"\"\n",
    "    def __init__(self, images, batch_size, shuffle=True, target_size=224):\n",
    "        self.images = images\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.target_size = target_size\n",
    "        self.indices = np.arange(len(images))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.images) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indices = self.indices[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch = [self.images[i] for i in batch_indices]\n",
    "        inputs = np.array([preprocess_input(x[0]) for x in batch])\n",
    "        targets = np.array([preprocess_input(x[1]) for x in batch])\n",
    "        return inputs, targets\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indices)\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "def load_images_from_folder(folder_path, target_size):\n",
    "    \"\"\"\n",
    "    Load images from a folder and resize them to the specified target size.\n",
    "\n",
    "    Parameters:\n",
    "        folder_path (str or Path): the path to the folder containing the images.\n",
    "        target_size (int): the size to which the images should be resized (assumed to be square).\n",
    "\n",
    "    Returns:\n",
    "        a list of preprocessed input and target images.\n",
    "    \"\"\"\n",
    "    image_paths = sorted(glob.glob(os.path.join(folder_path, '*.jpg')))\n",
    "    images = []\n",
    "    for path in image_paths:\n",
    "        image = load_img(path, target_size=(target_size, target_size))\n",
    "        input_image = img_to_array(image)\n",
    "        target_path = Path(path.replace('foggy', 'clear'))\n",
    "        target_path = target_path.parent / (target_path.stem + '.jpg')\n",
    "        target_image = img_to_array(load_img(target_path, target_size=(target_size, target_size)))\n",
    "        images.append((input_image, target_image))\n",
    "    return images\n",
    "\n",
    "\n",
    "def supervised_train(foggy_folder_path, clear_folder_path, num_epochs, batch_size, target_size):\n",
    "    \"\"\"\n",
    "    Train the DehazeNet model using supervised learning.\n",
    "\n",
    "    Parameters:\n",
    "        foggy_folder_path (str or Path): the path to the folder containing the foggy images.\n",
    "        clear_folder_path (str or Path): the path to the folder containing the corresponding clear images.\n",
    "        num_epochs (int): the number of epochs to train for.\n",
    "        batch_size (int): the batch size to use during training.\n",
    "        target_size (int): the size to which the images should be resized (assumed to be square).\n",
    "\n",
    "    Returns:\n",
    "        a Keras model object trained on the input data.\n",
    "    \"\"\"\n",
    "    # Load and preprocess the images\n",
    "    train_images = load_images_from_folder(foggy_folder_path, target_size)\n",
    "    val_images = load_images_from_folder(clear_folder_path, target_size)\n",
    "\n",
    "    # Create data generators for loading and preprocessing images in batches\n",
    "    train_generator = ImageSequence(train_images, batch_size=batch_size, shuffle=True)\n",
    "    val_generator = ImageSequence(val_images, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "    # Build and compile the DehazeNet model\n",
    "    num_channels = 3  # Assume RGB input images\n",
    "    model = build_dehazenet_model(target_size, num_channels)\n",
    "    model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "    # Train the DehazeNet model using supervised learning\n",
    "    early_stopping = callbacks.EarlyStopping(patience=3, restore_best_weights=True)\n",
    "    model.fit(\n",
    "        train_generator,\n",
    "        epochs=num_epochs,\n",
    "        steps_per_epoch=len(train_images) // batch_size,\n",
    "        validation_data=val_generator,\n",
    "        validation_steps=len(val_images) // batch_size,\n",
    "        callbacks=[early_stopping]\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    foggy_folder_path = Path(\"C:/Users/HP/Pictures/clearFoggy/Foggy/\")  # Specify the folder path containing the foggy images\n",
    "    clear_folder_path = Path(\"C:/Users/HP/Pictures/clearFoggy/Clear/\")  # Specify the folder path containing the clear images\n",
    "\n",
    "    target_size = 32  # Specify the desired target size for preprocessing\n",
    "\n",
    "    foggy_images = load_images_from_folder(foggy_folder_path, target_size)\n",
    "    clear_images = load_images_from_folder(clear_folder_path, target_size)\n",
    "\n",
    "    print(\"Number of foggy images:\", len(foggy_images))\n",
    "    print(\"Number of clear images:\", len(clear_images))\n",
    "\n",
    "    # Train the DehazeNet model\n",
    "    num_epochs = 10\n",
    "    batch_size = 32\n",
    "    model = supervised_train(foggy_folder_path, clear_folder_path, num_epochs, batch_size, target_size)\n",
    "\n",
    "    # Evaluate the DehazeNet model on a test image (optional)\n",
    "    test_image_path = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Fog/foggy-001.jpg\"\n",
    "    test_image = Image.open(test_image_path)\n",
    "    test_foggy_image = preprocess_image(test_image, target_size)\n",
    "    test_foggy_image = np.expand_dims(test_foggy_image, axis=0)\n",
    "    predicted_clear_image = model.predict(test_foggy_image)\n",
    "    plt.imshow(test_foggy_image[0])\n",
    "    plt.show()\n",
    "    plt.imshow(predicted_clear_image[0])\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pm3bap",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
