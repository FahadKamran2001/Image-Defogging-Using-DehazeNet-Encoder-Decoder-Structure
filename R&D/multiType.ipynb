{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Data cardinality is ambiguous:\n  x sizes: 5280\n  y sizes: 330\nMake sure all arrays contain the same number of samples.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 77\u001b[0m\n\u001b[0;32m     74\u001b[0m model\u001b[39m.\u001b[39mcompile(optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m, loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmean_squared_error\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m     76\u001b[0m \u001b[39m# Train the model\u001b[39;00m\n\u001b[1;32m---> 77\u001b[0m model\u001b[39m.\u001b[39;49mfit(foggy_images, clear_images, epochs\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, batch_size\u001b[39m=\u001b[39;49m\u001b[39m4\u001b[39;49m)\n\u001b[0;32m     79\u001b[0m \u001b[39m# Save the trained model\u001b[39;00m\n\u001b[0;32m     80\u001b[0m model\u001b[39m.\u001b[39msave(\u001b[39m\"\u001b[39m\u001b[39mfoggy_to_clear_model.h5\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[0;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\lib\\site-packages\\keras\\engine\\data_adapter.py:1851\u001b[0m, in \u001b[0;36m_check_data_cardinality\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m   1844\u001b[0m     msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m  \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m sizes: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\\n\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(\n\u001b[0;32m   1845\u001b[0m         label,\n\u001b[0;32m   1846\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39m, \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin(\n\u001b[0;32m   1847\u001b[0m             \u001b[39mstr\u001b[39m(i\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m tf\u001b[39m.\u001b[39mnest\u001b[39m.\u001b[39mflatten(single_data)\n\u001b[0;32m   1848\u001b[0m         ),\n\u001b[0;32m   1849\u001b[0m     )\n\u001b[0;32m   1850\u001b[0m msg \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mMake sure all arrays contain the same number of samples.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m-> 1851\u001b[0m \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(msg)\n",
      "\u001b[1;31mValueError\u001b[0m: Data cardinality is ambiguous:\n  x sizes: 5280\n  y sizes: 330\nMake sure all arrays contain the same number of samples."
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, UpSampling2D\n",
    "\n",
    "# Define the paths to the clear and foggy image folders\n",
    "clear_folder = \"C:/Users/HP/Downloads/frida2/frida2/\"\n",
    "foggy_homogeneous_folder = \"C:/Users/HP/Downloads/frida2/frida2/\"\n",
    "foggy_heterogeneous_folder = \"C:/Users/HP/Downloads/frida2/frida2/\"\n",
    "foggy_cloudy_homogeneous_folder = \"C:/Users/HP/Downloads/frida2/frida2/\"\n",
    "foggy_cloudy_heterogeneous_folder = \"C:/Users/HP/Downloads/frida2/frida2/\"\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 64\n",
    "image_width = 64\n",
    "num_channels = 3\n",
    "\n",
    "# Load the clear and foggy images\n",
    "clear_images = []\n",
    "foggy_images = []\n",
    "\n",
    "for filename in os.listdir(clear_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        clear_img = cv2.imread(os.path.join(clear_folder, filename))\n",
    "        foggy_homogeneous_filenames = [filename.replace(\"LIma\", \"U080\")] * 4  # Replace clear image name with corresponding homogeneous foggy image names\n",
    "        foggy_heterogeneous_filenames = [filename.replace(\"LIma\", \"K080\")] * 4  # Replace clear image name with corresponding heterogeneous foggy image names\n",
    "        foggy_cloudy_homogeneous_filenames = [filename.replace(\"LIma\", \"L080\")] * 4  # Replace clear image name with corresponding cloudy homogeneous foggy image names\n",
    "        foggy_cloudy_heterogeneous_filenames = [filename.replace(\"LIma\", \"M080\")] * 4  # Replace clear image name with corresponding cloudy heterogeneous foggy image names\n",
    "        \n",
    "        foggy_homogeneous_imgs = []\n",
    "        foggy_heterogeneous_imgs = []\n",
    "        foggy_cloudy_homogeneous_imgs = []\n",
    "        foggy_cloudy_heterogeneous_imgs = []\n",
    "        \n",
    "        for f_h in foggy_homogeneous_filenames:\n",
    "            foggy_homogeneous_imgs.append(cv2.imread(os.path.join(foggy_homogeneous_folder, f_h)))\n",
    "        for f_h in foggy_heterogeneous_filenames:\n",
    "            foggy_heterogeneous_imgs.append(cv2.imread(os.path.join(foggy_heterogeneous_folder, f_h)))\n",
    "        for f_h in foggy_cloudy_homogeneous_filenames:\n",
    "            foggy_cloudy_homogeneous_imgs.append(cv2.imread(os.path.join(foggy_cloudy_homogeneous_folder, f_h)))\n",
    "        for f_h in foggy_cloudy_heterogeneous_filenames:\n",
    "            foggy_cloudy_heterogeneous_imgs.append(cv2.imread(os.path.join(foggy_cloudy_heterogeneous_folder, f_h)))\n",
    "        \n",
    "        clear_img = cv2.resize(clear_img, (image_width, image_height))\n",
    "        foggy_homogeneous_imgs = [cv2.resize(img, (image_width, image_height)) for img in foggy_homogeneous_imgs]\n",
    "        foggy_heterogeneous_imgs = [cv2.resize(img, (image_width, image_height)) for img in foggy_heterogeneous_imgs]\n",
    "        foggy_cloudy_homogeneous_imgs = [cv2.resize(img, (image_width, image_height)) for img in foggy_cloudy_homogeneous_imgs]\n",
    "        foggy_cloudy_heterogeneous_imgs = [cv2.resize(img, (image_width, image_height)) for img in foggy_cloudy_heterogeneous_imgs]\n",
    "        \n",
    "        clear_images.append(clear_img)\n",
    "        foggy_images.extend(foggy_homogeneous_imgs)\n",
    "        foggy_images.extend(foggy_heterogeneous_imgs)\n",
    "        foggy_images.extend(foggy_cloudy_homogeneous_imgs)\n",
    "        foggy_images.extend(foggy_cloudy_heterogeneous_imgs)\n",
    "\n",
    "# Convert the lists of images to numpy arrays\n",
    "clear_images = np.array(clear_images)\n",
    "foggy_images = np.array(foggy_images)\n",
    "\n",
    "# Normalize pixel values to range between 0 and 1\n",
    "clear_images = clear_images.astype('float32') / 255.0\n",
    "foggy_images = foggy_images.astype('float32') / 255.0\n",
    "\n",
    "# Define the CNN model architecture\n",
    "model = Sequential()\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same', input_shape=(image_height, image_width, num_channels)))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(128, (3, 3), activation='relu', padding='same'))\n",
    "model.add(Conv2D(num_channels, (3, 3), activation='relu', padding='same'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(foggy_images, clear_images, epochs=5, batch_size=4)\n",
    "\n",
    "# Save the trained model\n",
    "model.save(\"foggy_to_clear_model.h5\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import os\n",
    "\n",
    "source_folder = \"C:\\Users\\HP\\Documents\\Semester (summer)\\Aim Lab Internship\\Multi fog\\U\"  # Folder containing the images\n",
    "target_folder = \"converted\"  # Folder to save the converted images\n",
    "\n",
    "# Create the target folder if it doesn't exist\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder)\n",
    "\n",
    "# Iterate through the files in the source folder\n",
    "for filename in os.listdir(source_folder):\n",
    "    if filename.startswith(\"U\") and filename.endswith(\".png\"):\n",
    "        # Extract the desired part of the filename\n",
    "        new_filename = filename[1:]\n",
    "\n",
    "        # Build the source and target file paths\n",
    "        source_path = os.path.join(source_folder, filename)\n",
    "        target_path = os.path.join(target_folder, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        os.rename(source_path, target_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 64\n",
    "image_width = 64\n",
    "num_channels = 3\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"foggy_to_clear_model.h5\")\n",
    "\n",
    "# Load a foggy image for testing\n",
    "foggy_image_path = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Fog/foggy-001.jpg\"\n",
    "foggy_image = cv2.imread(foggy_image_path)\n",
    "\n",
    "# Resize the foggy image to the desired size\n",
    "foggy_image = cv2.resize(foggy_image, (image_width, image_height))\n",
    "\n",
    "# Preprocess the foggy image\n",
    "foggy_image = foggy_image.astype('float32') / 255.0\n",
    "foggy_image = np.expand_dims(foggy_image, axis=0)\n",
    "\n",
    "# Use the model to predict the clear image\n",
    "clear_image = model.predict(foggy_image)\n",
    "\n",
    "# Rescale the pixel values to the original range\n",
    "clear_image = clear_image * 255.0\n",
    "clear_image = clear_image.astype('uint8')\n",
    "\n",
    "# Reshape the clear image\n",
    "clear_image = np.squeeze(clear_image, axis=0)\n",
    "\n",
    "# Display the clear image\n",
    "cv2.imshow(\"Clear Image\", clear_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
