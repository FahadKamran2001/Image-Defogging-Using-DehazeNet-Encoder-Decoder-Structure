{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "IMAGE NAME FORMATTING TO BE THE SAME\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "\n",
    "U_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/U/\"  # Folder containing the  U images\n",
    "Utarget_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/U/\"  # Folder to save the converted images\n",
    "\n",
    "L_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/L/\"  # Folder containing the  L images\n",
    "Ltarget_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/L/\"  # Folder to save the converted images\n",
    "\n",
    "Llma_folder = \"C:/Users/HP\\Documents/Semester (summer)/Aim Lab Internship/Multi fog/Llma/\"  # Folder containing the  Llma images\n",
    "Llmatarget_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/Llma/\"  # Folder to save the converted images\n",
    "\n",
    "M_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/M/\"  # Folder containing the  M images\n",
    "Mtarget_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/M/\"  # Folder to save the converted images\n",
    "\n",
    "K_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/K/\"  # Folder containing the  K images\n",
    "Ktarget_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/K/\"  # Folder to save the converted images\n",
    "\n",
    "#for U\n",
    "# Create the target folder if it doesn't exist\n",
    "if not os.path.exists(Utarget_folder):\n",
    "    os.makedirs(Utarget_folder)\n",
    "\n",
    "# Iterate through the files in the source folder\n",
    "for filename in os.listdir(U_folder):\n",
    "    if filename.startswith(\"U080-\") and filename.endswith(\".png\"):\n",
    "        # Extract the desired part of the filename\n",
    "        new_filename = filename.split(\"-\")[1]\n",
    "\n",
    "        # Build the source and target file paths\n",
    "        source_path = os.path.join(U_folder, filename)\n",
    "        target_path = os.path.join(Utarget_folder, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        os.rename(source_path, target_path)\n",
    "   \n",
    "   \n",
    "#for L     \n",
    "# Create the target folder if it doesn't exist\n",
    "if not os.path.exists(Ltarget_folder):\n",
    "    os.makedirs(Ltarget_folder)\n",
    "\n",
    "# Iterate through the files in the source folder\n",
    "for filename in os.listdir(L_folder):\n",
    "    if filename.startswith(\"L080-\") and filename.endswith(\".png\"):\n",
    "        # Extract the desired part of the filename\n",
    "        new_filename = filename.split(\"-\")[1]\n",
    "\n",
    "        # Build the source and target file paths\n",
    "        source_path = os.path.join(L_folder, filename)\n",
    "        target_path = os.path.join(Ltarget_folder, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        os.rename(source_path, target_path)\n",
    "        \n",
    "   \n",
    "   \n",
    "#for Llma    \n",
    "# Create the target folder if it doesn't exist\n",
    "if not os.path.exists(Llmatarget_folder):\n",
    "    os.makedirs(Llmatarget_folder)\n",
    "\n",
    "# Iterate through the files in the source folder\n",
    "for filename in os.listdir(Llma_folder):\n",
    "    if filename.startswith(\"LIma-\") and filename.endswith(\".png\"):\n",
    "        # Extract the desired part of the filename\n",
    "        new_filename = filename.split(\"-\")[1]\n",
    "\n",
    "        # Build the source and target file paths\n",
    "        source_path = os.path.join(Llma_folder, filename)\n",
    "        target_path = os.path.join(Llmatarget_folder, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        os.rename(source_path, target_path)\n",
    "        \n",
    "        \n",
    "#for M    \n",
    "# Create the target folder if it doesn't exist\n",
    "if not os.path.exists(Mtarget_folder):\n",
    "    os.makedirs(Mtarget_folder)\n",
    "\n",
    "# Iterate through the files in the source folder\n",
    "for filename in os.listdir(M_folder):\n",
    "    if filename.startswith(\"M080-\") and filename.endswith(\".png\"):\n",
    "        # Extract the desired part of the filename\n",
    "        new_filename = filename.split(\"-\")[1]\n",
    "\n",
    "        # Build the source and target file paths\n",
    "        source_path = os.path.join(M_folder, filename)\n",
    "        target_path = os.path.join(Mtarget_folder, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        os.rename(source_path, target_path)\n",
    "        \n",
    "        \n",
    "        \n",
    "#for K    \n",
    "# Create the target folder if it doesn't exist\n",
    "if not os.path.exists(Ktarget_folder):\n",
    "    os.makedirs(Ktarget_folder)\n",
    "\n",
    "# Iterate through the files in the source folder\n",
    "for filename in os.listdir(K_folder):\n",
    "    if filename.startswith(\"K080-\") and filename.endswith(\".png\"):\n",
    "        # Extract the desired part of the filename\n",
    "        new_filename = filename.split(\"-\")[1]\n",
    "\n",
    "        # Build the source and target file paths\n",
    "        source_path = os.path.join(K_folder, filename)\n",
    "        target_path = os.path.join(Ktarget_folder, new_filename)\n",
    "\n",
    "        # Rename and move the file\n",
    "        os.rename(source_path, target_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14/14 [==============================] - 37s 2s/step - loss: 0.2264\n",
      "14/14 [==============================] - 54s 4s/step - loss: 0.1683\n",
      "14/14 [==============================] - 57s 4s/step - loss: 0.1135\n",
      "14/14 [==============================] - 55s 4s/step - loss: 0.1304\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TRAINING ALL 4 MODELS\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "U_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/U/\"  # Folder containing the  U images\n",
    "L_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/L/\"  # Folder containing the  L images\n",
    "Llma_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/Llma/\"  # Folder containing the  Llma images\n",
    "M_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/M/\"  # Folder containing the  M images\n",
    "K_folder = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/K/\"  # Folder containing the  K images\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 64\n",
    "image_width = 64\n",
    "\n",
    "\n",
    "\"\"\" K Images Model\"\"\"\n",
    "# Load the clear and foggy images\n",
    "clear_images = []\n",
    "Kfoggy_Images = []\n",
    "for filename in os.listdir(K_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        K_imgs = cv2.imread(os.path.join(K_folder, filename))\n",
    "        clear_filename = os.path.splitext(filename)[0] + \".png\"  # Assuming clear images have .jpg extension\n",
    "        clear_img = cv2.imread(os.path.join(Llma_folder, clear_filename))\n",
    "        K_imgs = cv2.resize(K_imgs, (image_width, image_height))\n",
    "        clear_img = cv2.resize(clear_img, (image_width, image_height))\n",
    "        Kfoggy_Images.append(K_imgs)\n",
    "        clear_images.append(clear_img)\n",
    "# Convert the lists of images to numpy arrays\n",
    "clear_images = np.array(clear_images)\n",
    "Kfoggy_Images = np.array(Kfoggy_Images)\n",
    "# Normalize pixel values to range between 0 and 1\n",
    "clear_images = clear_images.astype('float32') / 255.0\n",
    "Kfoggy_Images = Kfoggy_Images.astype('float32') / 255.0\n",
    "# Create the CNN model for K\n",
    "num_channels = 3\n",
    "modelK = Sequential()\n",
    "modelK.add(Conv2D(256, (3, 3), activation='relu', padding='same', input_shape=(image_width, image_height, num_channels)))\n",
    "modelK.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelK.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelK.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelK.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelK.add(Conv2D(num_channels, (3, 3), activation='relu', padding='same'))\n",
    "# Compile the model\n",
    "modelK.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Train the model\n",
    "modelK.fit(Kfoggy_Images, clear_images, epochs=1, batch_size=5)\n",
    "# Save the trained model\n",
    "modelK.save('trainedK_model.h5')\n",
    "\n",
    "\n",
    "\"\"\" L Images Model\"\"\"\n",
    "# Load the clear and foggy images\n",
    "clear_images = []\n",
    "Lfoggy_Images = []\n",
    "for filename in os.listdir(K_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        L_imgs = cv2.imread(os.path.join(L_folder, filename))\n",
    "        clear_filename = os.path.splitext(filename)[0] + \".png\"  # Assuming clear images have .jpg extension\n",
    "        clear_img = cv2.imread(os.path.join(Llma_folder, clear_filename))\n",
    "        L_imgs = cv2.resize(L_imgs, (image_width, image_height))\n",
    "        clear_img = cv2.resize(clear_img, (image_width, image_height))\n",
    "        Lfoggy_Images.append(L_imgs)\n",
    "        clear_images.append(clear_img)\n",
    "# Convert the lists of images to numpy arrays\n",
    "clear_images = np.array(clear_images)\n",
    "Lfoggy_Images = np.array(Lfoggy_Images)\n",
    "# Normalize pixel values to range between 0 and 1\n",
    "clear_images = clear_images.astype('float32') / 255.0\n",
    "Lfoggy_Images = Lfoggy_Images.astype('float32') / 255.0\n",
    "# Create the CNN model for K\n",
    "num_channels = 3\n",
    "modelL = Sequential()\n",
    "modelL.add(Conv2D(256, (3, 3), activation='relu', padding= 'same', input_shape=(image_width, image_height, num_channels)))\n",
    "modelL.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelL.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelL.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelL.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelL.add(Conv2D(num_channels, (3, 3), activation='relu', padding='same'))\n",
    "# Compile the model\n",
    "modelL.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Train the model\n",
    "modelL.fit(Lfoggy_Images, clear_images, epochs=1, batch_size=5)\n",
    "# Save the trained model\n",
    "modelL.save('trainedL_model.h5')\n",
    "\n",
    "\n",
    "\"\"\" M Images Model\"\"\"\n",
    "# Load the clear and foggy images\n",
    "clear_images = []\n",
    "Mfoggy_Images = []\n",
    "for filename in os.listdir(M_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        M_imgs = cv2.imread(os.path.join(M_folder, filename))\n",
    "        clear_filename = os.path.splitext(filename)[0] + \".png\"  # Assuming clear images have .jpg extension\n",
    "        clear_img = cv2.imread(os.path.join(Llma_folder, clear_filename))\n",
    "        M_imgs = cv2.resize(M_imgs, (image_width, image_height))\n",
    "        clear_img = cv2.resize(clear_img, (image_width, image_height))\n",
    "        Mfoggy_Images.append(M_imgs)\n",
    "        clear_images.append(clear_img)\n",
    "# Convert the lists of images to numpy arrays\n",
    "clear_images = np.array(clear_images)\n",
    "Mfoggy_Images = np.array(Mfoggy_Images)\n",
    "# Normalize pixel values to range between 0 and 1\n",
    "clear_images = clear_images.astype('float32') / 255.0\n",
    "Mfoggy_Images = Mfoggy_Images.astype('float32') / 255.0\n",
    "# Create the CNN model for K\n",
    "num_channels = 3\n",
    "modelM = Sequential()\n",
    "modelM.add(Conv2D(256, (3, 3), activation='relu', padding= 'same', input_shape=(image_width, image_height, num_channels)))\n",
    "modelM.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelM.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelM.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelM.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelM.add(Conv2D(num_channels, (3, 3), activation='relu', padding='same'))\n",
    "# Compile the model\n",
    "modelM.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Train the model\n",
    "modelM.fit(Mfoggy_Images, clear_images, epochs=1, batch_size=5)\n",
    "# Save the trained model\n",
    "modelM.save('trainedM_model.h5')\n",
    "\n",
    "\n",
    "\"\"\" U Images Model\"\"\"\n",
    "# Load the clear and foggy images\n",
    "clear_images = []\n",
    "Ufoggy_Images = []\n",
    "for filename in os.listdir(U_folder):\n",
    "    if filename.endswith(\".png\"):\n",
    "        U_imgs = cv2.imread(os.path.join(U_folder, filename))\n",
    "        clear_filename = os.path.splitext(filename)[0] + \".png\"  # Assuming clear images have .jpg extension\n",
    "        clear_img = cv2.imread(os.path.join(Llma_folder, clear_filename))\n",
    "        U_imgs = cv2.resize(U_imgs, (image_width, image_height))\n",
    "        clear_img = cv2.resize(clear_img, (image_width, image_height))\n",
    "        Ufoggy_Images.append(U_imgs)\n",
    "        clear_images.append(clear_img)\n",
    "# Convert the lists of images to numpy arrays\n",
    "clear_images = np.array(clear_images)\n",
    "Ufoggy_Images = np.array(Ufoggy_Images)\n",
    "# Normalize pixel values to range between 0 and 1\n",
    "clear_images = clear_images.astype('float32') / 255.0\n",
    "Ufoggy_Images = Ufoggy_Images.astype('float32') / 255.0\n",
    "# Create the CNN model for K\n",
    "num_channels = 3\n",
    "modelU = Sequential()\n",
    "modelU.add(Conv2D(256, (3, 3), activation='relu', padding= 'same', input_shape=(image_width, image_height, num_channels)))\n",
    "modelU.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelU.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelU.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelU.add(Conv2D(256, (3, 3), activation='relu', padding='same'))\n",
    "modelU.add(Conv2D(num_channels, (3, 3), activation='relu', padding='same'))\n",
    "# Compile the model\n",
    "modelU.compile(optimizer='adam', loss='mean_squared_error')\n",
    "# Train the model\n",
    "modelU.fit(Ufoggy_Images, clear_images, epochs=1, batch_size=5)\n",
    "# Save the trained model\n",
    "modelU.save('trainedU_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 494ms/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TESTING K MODEL\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 64\n",
    "image_width = 64\n",
    "num_channels = 3\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"trainedK_model.h5\")\n",
    "\n",
    "# Load a foggy image for testing\n",
    "foggy_image_path = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Fog/foggy-001.jpg\"\n",
    "foggy_image = cv2.imread(foggy_image_path)\n",
    "\n",
    "# Resize the foggy image to the desired size\n",
    "foggy_image = cv2.resize(foggy_image, (image_width, image_height))\n",
    "\n",
    "# Preprocess the foggy image\n",
    "foggy_image = foggy_image.astype('float32') / 255.0\n",
    "foggy_image = np.expand_dims(foggy_image, axis=0)\n",
    "\n",
    "# Use the model to predict the clear image\n",
    "clear_image = model.predict(foggy_image)\n",
    "\n",
    "# Rescale the pixel values to the original range\n",
    "clear_image = clear_image * 255.0\n",
    "clear_image = clear_image.astype('uint8')\n",
    "\n",
    "# Reshape the clear image\n",
    "clear_image = np.squeeze(clear_image, axis=0)\n",
    "\n",
    "# Display the clear image\n",
    "cv2.imshow(\"Clear Image\", clear_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 5 calls to <function Model.make_predict_function.<locals>.predict_function at 0x0000013100BFC9D0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 642ms/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TESTING U MODEL\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 64\n",
    "image_width = 64\n",
    "num_channels = 3\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"trainedU_model.h5\")\n",
    "\n",
    "# Load a foggy image for testing\n",
    "foggy_image_path = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Fog/foggy-001.jpg\"\n",
    "foggy_image = cv2.imread(foggy_image_path)\n",
    "\n",
    "# Resize the foggy image to the desired size\n",
    "foggy_image = cv2.resize(foggy_image, (image_width, image_height))\n",
    "\n",
    "# Preprocess the foggy image\n",
    "foggy_image = foggy_image.astype('float32') / 255.0\n",
    "foggy_image = np.expand_dims(foggy_image, axis=0)\n",
    "\n",
    "# Use the model to predict the clear image\n",
    "clear_image = model.predict(foggy_image)\n",
    "\n",
    "# Rescale the pixel values to the original range\n",
    "clear_image = clear_image * 255.0\n",
    "clear_image = clear_image.astype('uint8')\n",
    "\n",
    "# Reshape the clear image\n",
    "clear_image = np.squeeze(clear_image, axis=0)\n",
    "\n",
    "# Display the clear image\n",
    "cv2.imshow(\"Clear Image\", clear_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 334ms/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TESTING M MODEL\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 64\n",
    "image_width = 64\n",
    "num_channels = 3\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"trainedM_model.h5\")\n",
    "\n",
    "# Load a foggy image for testing\n",
    "foggy_image_path = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Fog/foggy-001.jpg\"\n",
    "foggy_image = cv2.imread(foggy_image_path)\n",
    "\n",
    "# Resize the foggy image to the desired size\n",
    "foggy_image = cv2.resize(foggy_image, (image_width, image_height))\n",
    "\n",
    "# Preprocess the foggy image\n",
    "foggy_image = foggy_image.astype('float32') / 255.0\n",
    "foggy_image = np.expand_dims(foggy_image, axis=0)\n",
    "\n",
    "# Use the model to predict the clear image\n",
    "clear_image = model.predict(foggy_image)\n",
    "\n",
    "# Rescale the pixel values to the original range\n",
    "clear_image = clear_image * 255.0\n",
    "clear_image = clear_image.astype('uint8')\n",
    "\n",
    "# Reshape the clear image\n",
    "clear_image = np.squeeze(clear_image, axis=0)\n",
    "\n",
    "# Display the clear image\n",
    "cv2.imshow(\"Clear Image\", clear_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 243ms/step\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "TESTING L MODEL\n",
    "\"\"\"\n",
    "import cv2\n",
    "import numpy as np\n",
    "from keras.models import load_model\n",
    "\n",
    "# Set the desired image size\n",
    "image_height = 64\n",
    "image_width = 64\n",
    "num_channels = 3\n",
    "\n",
    "# Load the trained model\n",
    "model = load_model(\"trainedL_model.h5\")\n",
    "\n",
    "# Load a foggy image for testing\n",
    "foggy_image_path = \"C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Fog/foggy-001.jpg\"\n",
    "foggy_image = cv2.imread(foggy_image_path)\n",
    "\n",
    "# Resize the foggy image to the desired size\n",
    "foggy_image = cv2.resize(foggy_image, (image_width, image_height))\n",
    "\n",
    "# Preprocess the foggy image\n",
    "foggy_image = foggy_image.astype('float32') / 255.0\n",
    "foggy_image = np.expand_dims(foggy_image, axis=0)\n",
    "\n",
    "# Use the model to predict the clear image\n",
    "clear_image = model.predict(foggy_image)\n",
    "\n",
    "# Rescale the pixel values to the original range\n",
    "clear_image = clear_image * 255.0\n",
    "clear_image = clear_image.astype('uint8')\n",
    "\n",
    "# Reshape the clear image\n",
    "clear_image = np.squeeze(clear_image, axis=0)\n",
    "\n",
    "# Display the clear image\n",
    "cv2.imshow(\"Clear Image\", clear_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data augmentation complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the path to the original image folder\n",
    "original_folder = 'C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/K/'\n",
    "# Set the path to the folder where augmented images will be saved\n",
    "augmented_folder = 'C:/Users/HP/Documents/Semester (summer)/Aim Lab Internship/Multi fog/K/Generated/'\n",
    "\n",
    "# Create the augmented images folder within the original image folder\n",
    "new_folder = os.path.join(original_folder, 'augmented')\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# Set the desired augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Iterate through the images in the original folder and generate augmented images\n",
    "for filename in os.listdir(original_folder):\n",
    "    if filename.endswith('.png'):  # Adjust the file extension if necessary\n",
    "        img_path = os.path.join(original_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "\n",
    "        # Reshape the image to have a batch dimension\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "\n",
    "        # Generate augmented images\n",
    "        augmented_images = datagen.flow(img, batch_size=1, save_to_dir=new_folder, save_prefix='aug_', save_format='png')\n",
    "\n",
    "        # Generate and save the augmented images\n",
    "        for i, augmented_image in enumerate(augmented_images):\n",
    "            if i >= 10:  # Generate 10 augmented images per original image\n",
    "                break\n",
    "\n",
    "# Confirm completion\n",
    "print('Data augmentation complete.')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Image Augmentation \n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Set the path to the original image folder\n",
    "original_folder = 'path_to_original_images_folder'\n",
    "# Set the path to the folder where augmented images will be saved\n",
    "augmented_folder = 'path_to_augmented_images_folder'\n",
    "\n",
    "# Create the augmented images folder within the original image folder\n",
    "new_folder = os.path.join(original_folder, 'augmented')\n",
    "os.makedirs(new_folder, exist_ok=True)\n",
    "\n",
    "# Set the desired augmentation parameters\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=False,\n",
    "    zoom_range=0.1\n",
    ")\n",
    "\n",
    "# Iterate through the images in the original folder and generate augmented images\n",
    "for filename in os.listdir(original_folder):\n",
    "    if filename.endswith('.png'):  # Adjust the file extension if necessary\n",
    "        img_path = os.path.join(original_folder, filename)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)  # Convert BGR to RGB\n",
    "\n",
    "        # Reshape the image to have a batch dimension\n",
    "        img = img.reshape((1,) + img.shape)\n",
    "\n",
    "        # Generate augmented images\n",
    "        augmented_images = datagen.flow(img, batch_size=1, save_to_dir=new_folder, save_prefix='aug_', save_format='png')\n",
    "\n",
    "        # Generate and save the augmented images\n",
    "        num_augmented = 0\n",
    "        for augmented_image in augmented_images:\n",
    "            num_augmented += 1\n",
    "            if num_augmented >= 10:  # Generate 10 augmented images per original image\n",
    "                break\n",
    "\n",
    "        # Break the loop if the desired number of augmented images is reached\n",
    "\n",
    "# Confirm completion\n",
    "print('Data augmentation complete.')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
